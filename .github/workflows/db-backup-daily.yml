name: DB Backup (daily)

on:
  schedule:
    - cron: "0 5 * * *" # Runs at midnight EST (5 AM UTC)
  workflow_dispatch:

permissions:
  contents: read

jobs:
  db-backup:
    runs-on: ubuntu-latest

    env:
      RETENTION_DAYS: 365
      PG_VERSION: "17"

    steps:
      - name: Install PostgreSQL
        run: |
          sudo apt update
          yes '' | sudo /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh
          sudo apt install -y postgresql-${{ env.PG_VERSION }}

      - name: Set PostgreSQL binary path
        run: echo "POSTGRES=/usr/lib/postgresql/${{ env.PG_VERSION }}/bin" >> $GITHUB_ENV

      - name: Install AWS CLI
        run: |
          pip install awscli

      - name: Set file, folder and path variables
        run: |
          GZIP_NAME="$(date +'%B-%d-%Y@%H:%M:%S').sql.gz"
          UPLOAD_PATH="s3://${{ env.BACKUPS_R2_BUCKET_NAME }}/neon-db/${GZIP_NAME}"

          echo "GZIP_NAME=${GZIP_NAME}" >> $GITHUB_ENV
          echo "UPLOAD_PATH=${UPLOAD_PATH}" >> $GITHUB_ENV
        env:
          BACKUPS_R2_BUCKET_NAME: ${{ secrets.BACKUPS_R2_BUCKET_NAME }}

      - name: Run pg_dump
        run: |
          $POSTGRES/pg_dump -v ${{ env.DATABASE_URL }} | gzip > "${{ env.GZIP_NAME }}"
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}

      - name: Upload to Cloudflare R2
        run: |
          aws s3 cp "${{ env.GZIP_NAME }}" "${{ env.UPLOAD_PATH }}" \
            --endpoint-url ${{ env.BACKUPS_R2_ENDPOINT }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKUPS_R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKUPS_R2_SECRET_ACCESS_KEY }}
          BACKUPS_R2_ENDPOINT: ${{ secrets.BACKUPS_R2_ENDPOINT }}

